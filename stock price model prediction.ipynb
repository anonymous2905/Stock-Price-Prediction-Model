{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model Ridge for category large_cap\n",
      "Fitting model RandomForest for category large_cap\n",
      "Fitting model GradientBoosting for category large_cap\n",
      "Best model for large_cap: Ridge (MSE: 515.2925068308336)\n",
      "Fitting model Ridge for category mid_cap\n",
      "Fitting model RandomForest for category mid_cap\n",
      "Fitting model GradientBoosting for category mid_cap\n",
      "Best model for mid_cap: Ridge (MSE: 2182.6444153483794)\n",
      "Fitting model Ridge for category small_cap\n",
      "Fitting model RandomForest for category small_cap\n",
      "Fitting model GradientBoosting for category small_cap\n",
      "Best model for small_cap: Ridge (MSE: 1254.4709329117445)\n",
      "MSE for large_cap: 1164.812240943525\n",
      "MSE for mid_cap: 1321.330825289709\n",
      "MSE for small_cap: 1101.6917146382827\n"
     ]
    }
   ],
   "source": [
    "# Load data function\n",
    "def load_data(category):\n",
    "    data = pd.DataFrame()\n",
    "    directory = f\"./{category}/\"\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith(\".csv\"):\n",
    "            df = pd.read_csv(os.path.join(directory, file))\n",
    "            data = pd.concat([data, df], axis=0)\n",
    "    return data\n",
    "\n",
    "# Load data for each category\n",
    "large_cap_data = load_data(\"large_cap\")\n",
    "mid_cap_data = load_data(\"mid_cap\")\n",
    "small_cap_data = load_data(\"small_cap\")\n",
    "\n",
    "# Define features and target variable\n",
    "features = ['Open', 'High', 'Low', 'Volume']\n",
    "target = 'Close'\n",
    "\n",
    "# Train and evaluate models\n",
    "best_models = {}\n",
    "for category, train_data in [(\"large_cap\", large_cap_data), (\"mid_cap\", mid_cap_data), (\"small_cap\", small_cap_data)]:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train_data[features], train_data[target], test_size=0.4, random_state=42)\n",
    "    best_model_category = None\n",
    "    best_mse = float('inf')\n",
    "    for model_name, model in models.items():\n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('regressor', model)\n",
    "        ])\n",
    "        print(f\"Fitting model {model_name} for category {category}\")\n",
    "        grid_search = GridSearchCV(pipeline, param_grid[model_name], cv=3, scoring='neg_mean_squared_error')\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        mse = -grid_search.best_score_  # GridSearchCV uses neg_mean_squared_error\n",
    "        if mse < best_mse:\n",
    "            best_mse = mse\n",
    "            best_model_category = model_name\n",
    "            best_models[category] = grid_search.best_estimator_\n",
    "    print(f\"Best model for {category}: {best_model_category} (MSE: {best_mse})\")\n",
    "\n",
    "# Evaluate models on test data\n",
    "for category, model in best_models.items():\n",
    "    X_test = test_data[features]\n",
    "    y_test = test_data[target]\n",
    "    predictions = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    print(f\"MSE for {category}: {mse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date       Open       High        Low      Close  Adj Close    Volume\n",
      "0  2017-01-02  80.349998  84.916664  80.349998  84.483330  78.137337  10800348\n",
      "1  2017-01-03  85.933334  86.583336  84.000000  84.816666  78.445625   6187929\n",
      "2  2017-01-04  85.483330  85.966667  81.699997  82.366669  76.179672   9914781\n",
      "3  2017-01-05  82.833336  84.000000  80.133331  83.199997  76.950401   5573718\n",
      "4  2017-01-06  83.316666  84.766663  83.216667  83.650002  77.366600   2417802\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data from the CSV file\n",
    "data = pd.read_csv(\"small_cap/NBCC.NS_stock_data.csv\")\n",
    "\n",
    "# Now you can work with the data using pandas DataFrame operations\n",
    "print(data.head())  # Display the first few rows of the data\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
